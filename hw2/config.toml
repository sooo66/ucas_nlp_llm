[paths]
dataset = "news.2017.zh.shuffled.deduped"
tokenizer_name = "bert-base-chinese"
output_dir = "runs"

[training]
epochs = 5
batch_size = 32
num_workers = 2
learning_rate = 0.0003
weight_decay = 0.01
grad_clip = 1.0
seq_len = 128
seed = 42
device = "cuda"

[fnn]
context_size = 5
embedding_dim = 256
hidden_dim = 512

[rnn]
embedding_dim = 256
hidden_dim = 512

[transformer]
d_model = 512
num_heads = 8
num_layers = 6
ffn_dim = 2048
dropout = 0.1

[logging]
log_level = "INFO"
